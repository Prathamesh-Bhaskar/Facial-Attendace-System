{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4NOwkN1U+vc9NjwDATCNK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the matplotlib library\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "id": "zXb0Witp-FM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import uuid\n"
      ],
      "metadata": {
        "id": "0Y-_PLRx-KZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup paths for storing data\n",
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "ANC_PATH = os.path.join('data', 'anchor')\n",
        "\n",
        "# Make directories if they don't exist\n",
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)\n",
        "\n",
        "# Generate unique image name using UUID library\n",
        "os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n"
      ],
      "metadata": {
        "id": "cHhSJ9RW-UAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish a connection to the webcam\n",
        "cap = cv2.VideoCapture(0)\n"
      ],
      "metadata": {
        "id": "eXb89hXm-X2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a loop to collect images from webcam\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Crop frame to 250x250 pixels\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "\n",
        "    # Collect anchor images on 'a' keypress\n",
        "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        cv2.imwrite(imgname, frame)\n",
        "\n",
        "    # Collect positive images on 'p' keypress\n",
        "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        cv2.imwrite(imgname, frame)\n",
        "\n",
        "    # Show image\n",
        "    cv2.imshow('Image Collection', frame)\n",
        "\n",
        "    # Break loop on 'q' keypress\n",
        "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release webcam and close image window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "2SY5rFm5-X_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load anchor, positive, and negative images into datasets\n",
        "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(35)\n",
        "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(35)\n",
        "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(35)\n"
      ],
      "metadata": {
        "id": "6Pulqvp4-YIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset\n",
        "dir_test = anchor.as_numpy_iterator()\n",
        "print(dir_test.next())\n"
      ],
      "metadata": {
        "id": "zGR0pqYk-YNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images\n",
        "def preprocess(file_path):\n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    img = tf.image.resize(img,(100,100))\n",
        "    img = img/255.0\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "ArhwBG1n-YP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = preprocess('data\\\\anchor\\\\1a0464d9-7e22-11ee-a4d7-00933761849b.jpg')\n",
        "\n",
        "plt.imshow(img)\n"
      ],
      "metadata": {
        "id": "puZco2hN-YSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels for anchor-positive and anchor-negative pairs\n",
        "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)\n"
      ],
      "metadata": {
        "id": "o6j_I7M0-YVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels for classification\n",
        "class_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))\n",
        "iterator_labs = class_labels.as_numpy_iterator()\n",
        "iterator_labs.next()\n"
      ],
      "metadata": {
        "id": "FxBzXqHg-YXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images for training\n",
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return (preprocess(input_img), preprocess(validation_img), label)\n"
      ],
      "metadata": {
        "id": "ksEpqpz3-nL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = preprocess_twin(*examples)\n",
        "\n",
        "plt.imshow(res[1])\n"
      ],
      "metadata": {
        "id": "5frywECT-nQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build data loader pipeline\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1024)\n",
        "\n",
        "samples = data.as_numpy_iterator()\n",
        "samples.next()\n"
      ],
      "metadata": {
        "id": "K2WbHtO4-nUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide data into train and test partitions\n",
        "train_data = data.take(round(len(data)*0.7))\n",
        "train_data = train_data.batch(8)\n",
        "train_data = train_data.prefetch(4)\n",
        "\n",
        "test_data = data.skip(round(len(data)*0.7))\n",
        "test_data = test_data.take(round(len(data) *0.3))\n",
        "test_data = test_data.batch(8)\n",
        "test_data = test_data.prefetch(4)\n"
      ],
      "metadata": {
        "id": "2rTKyFDk-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture of the embedding model\n",
        "inp = Input(shape=(100,100,3), name='input_image')\n",
        "c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "m3 = MaxPooling2D(64\n"
      ],
      "metadata": {
        "id": "3jOv_Srz-vtl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}